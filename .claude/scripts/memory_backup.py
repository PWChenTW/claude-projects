#!/usr/bin/env python3
"""
è¨˜æ†¶å‚™ä»½è…³æœ¬ - Memory Backup Script
ç”¨æ–¼å‚™ä»½å’Œæ¢å¾©å°ˆæ¡ˆè¨˜æ†¶ç³»çµ±
"""

import os
import json
import shutil
import tarfile
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict

class MemoryBackup:
    """è¨˜æ†¶å‚™ä»½ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.memory_base = self.project_root / ".kiro" / "memory"
        self.backup_dir = self.project_root / ".kiro" / "backups"
        
        # ç¢ºä¿å‚™ä»½ç›®éŒ„å­˜åœ¨
        self.backup_dir.mkdir(parents=True, exist_ok=True)
    
    def create_backup(self, backup_name: Optional[str] = None) -> Path:
        """å‰µå»ºè¨˜æ†¶ç³»çµ±å‚™ä»½"""
        if not backup_name:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"memory_backup_{timestamp}"
        
        backup_file = self.backup_dir / f"{backup_name}.tar.gz"
        
        print(f"ğŸ“¦ å‰µå»ºå‚™ä»½: {backup_file.name}")
        
        # å‰µå»ºå‚™ä»½å…ƒæ•¸æ“š
        metadata = {
            "created": datetime.now().isoformat(),
            "backup_name": backup_name,
            "source": str(self.memory_base.relative_to(self.project_root)),
            "files_count": 0,
            "directories": []
        }
        
        # çµ±è¨ˆæ–‡ä»¶
        for root, dirs, files in os.walk(self.memory_base):
            root_path = Path(root)
            rel_path = root_path.relative_to(self.memory_base)
            metadata["directories"].append(str(rel_path))
            metadata["files_count"] += len(files)
        
        # å‰µå»ºè‡¨æ™‚å…ƒæ•¸æ“šæ–‡ä»¶
        metadata_file = self.backup_dir / f"{backup_name}_metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        # å‰µå»ºå£“ç¸®å‚™ä»½
        with tarfile.open(backup_file, "w:gz") as tar:
            # æ·»åŠ è¨˜æ†¶ç›®éŒ„
            tar.add(
                self.memory_base,
                arcname="memory",
                recursive=True
            )
            # æ·»åŠ å…ƒæ•¸æ“š
            tar.add(
                metadata_file,
                arcname="metadata.json"
            )
        
        # æ¸…ç†è‡¨æ™‚å…ƒæ•¸æ“šæ–‡ä»¶
        metadata_file.unlink()
        
        print(f"âœ… å‚™ä»½å®Œæˆ:")
        print(f"   - æ–‡ä»¶æ•¸: {metadata['files_count']}")
        print(f"   - ç›®éŒ„æ•¸: {len(metadata['directories'])}")
        print(f"   - å¤§å°: {backup_file.stat().st_size / 1024:.2f} KB")
        
        return backup_file
    
    def list_backups(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰å‚™ä»½"""
        backups = []
        
        for backup_file in self.backup_dir.glob("memory_backup_*.tar.gz"):
            # æå–å…ƒæ•¸æ“š
            try:
                with tarfile.open(backup_file, "r:gz") as tar:
                    # å˜—è©¦è®€å–å…ƒæ•¸æ“š
                    try:
                        metadata_info = tar.getmember("metadata.json")
                        f = tar.extractfile(metadata_info)
                        if f:
                            metadata = json.load(f)
                        else:
                            metadata = {}
                    except KeyError:
                        metadata = {}
                
                backups.append({
                    "file": backup_file.name,
                    "size": f"{backup_file.stat().st_size / 1024:.2f} KB",
                    "created": metadata.get("created", "unknown"),
                    "files_count": metadata.get("files_count", "unknown")
                })
            except Exception as e:
                print(f"âš ï¸  ç„¡æ³•è®€å–å‚™ä»½ {backup_file.name}: {e}")
        
        return sorted(backups, key=lambda x: x["file"], reverse=True)
    
    def restore_backup(self, backup_name: str, target_dir: Optional[Path] = None):
        """æ¢å¾©å‚™ä»½"""
        # æŸ¥æ‰¾å‚™ä»½æ–‡ä»¶
        if not backup_name.endswith(".tar.gz"):
            backup_name += ".tar.gz"
        
        backup_file = self.backup_dir / backup_name
        
        if not backup_file.exists():
            print(f"âŒ å‚™ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
            return False
        
        if target_dir is None:
            target_dir = self.memory_base
        
        print(f"ğŸ“‚ æ¢å¾©å‚™ä»½: {backup_file.name}")
        print(f"ğŸ“ ç›®æ¨™ä½ç½®: {target_dir}")
        
        # å‰µå»ºæ¢å¾©å‰å‚™ä»½
        if target_dir.exists():
            print("âš ï¸  ç›®æ¨™ç›®éŒ„å·²å­˜åœ¨ï¼Œå‰µå»ºæ¢å¾©å‰å‚™ä»½...")
            pre_restore_backup = f"pre_restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.create_backup(pre_restore_backup)
        
        # æ¸…ç©ºç›®æ¨™ç›®éŒ„
        if target_dir.exists():
            shutil.rmtree(target_dir)
        target_dir.mkdir(parents=True, exist_ok=True)
        
        # è§£å£“å‚™ä»½
        with tarfile.open(backup_file, "r:gz") as tar:
            # æå–è¨˜æ†¶ç›®éŒ„å…§å®¹
            for member in tar.getmembers():
                if member.name.startswith("memory/"):
                    # èª¿æ•´è·¯å¾‘
                    member.name = member.name[7:]  # ç§»é™¤ "memory/" å‰ç¶´
                    if member.name:  # ç¢ºä¿ä¸æ˜¯ç©ºè·¯å¾‘
                        tar.extract(member, target_dir)
        
        print(f"âœ… å‚™ä»½æ¢å¾©å®Œæˆï¼")
        return True
    
    def auto_backup(self, max_backups: int = 7):
        """è‡ªå‹•å‚™ä»½ï¼ˆä¿ç•™æœ€è¿‘Nå€‹å‚™ä»½ï¼‰"""
        print(f"ğŸ”„ åŸ·è¡Œè‡ªå‹•å‚™ä»½ (ä¿ç•™æœ€è¿‘ {max_backups} å€‹)")
        
        # å‰µå»ºæ–°å‚™ä»½
        new_backup = self.create_backup()
        
        # æ¸…ç†èˆŠå‚™ä»½
        backups = list(self.backup_dir.glob("memory_backup_*.tar.gz"))
        backups.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        if len(backups) > max_backups:
            for old_backup in backups[max_backups:]:
                print(f"ğŸ—‘ï¸  åˆªé™¤èˆŠå‚™ä»½: {old_backup.name}")
                old_backup.unlink()
        
        print(f"âœ… è‡ªå‹•å‚™ä»½å®Œæˆï¼Œç•¶å‰ä¿ç•™ {min(len(backups), max_backups)} å€‹å‚™ä»½")
    
    def export_memory(self, export_path: Path):
        """å°å‡ºè¨˜æ†¶ç³»çµ±ç‚ºå¯è®€æ ¼å¼"""
        export_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“¤ å°å‡ºè¨˜æ†¶ç³»çµ±åˆ°: {export_path}")
        
        # è¤‡è£½æ‰€æœ‰è¨˜æ†¶æ–‡ä»¶
        for memory_type in ["global", "project", "session"]:
            source = self.memory_base / memory_type
            if source.exists():
                target = export_path / memory_type
                shutil.copytree(source, target, dirs_exist_ok=True)
                print(f"   âœ“ å°å‡º {memory_type} è¨˜æ†¶")
        
        # ç”Ÿæˆç´¢å¼•æ–‡ä»¶
        index_content = ["# è¨˜æ†¶ç³»çµ±å°å‡ºç´¢å¼•\n"]
        index_content.append(f"å°å‡ºæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        for root, dirs, files in os.walk(export_path):
            level = root.replace(str(export_path), '').count(os.sep)
            indent = ' ' * 2 * level
            root_path = Path(root)
            index_content.append(f"{indent}- {root_path.name}/")
            
            sub_indent = ' ' * 2 * (level + 1)
            for file in files:
                index_content.append(f"{sub_indent}- {file}")
        
        index_file = export_path / "INDEX.md"
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(index_content))
        
        print(f"âœ… è¨˜æ†¶ç³»çµ±å°å‡ºå®Œæˆï¼")
        print(f"ğŸ“‹ ç´¢å¼•æ–‡ä»¶: {index_file}")


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è¨˜æ†¶ç³»çµ±å‚™ä»½å·¥å…·")
    parser.add_argument(
        "action",
        choices=["backup", "restore", "list", "auto", "export"],
        help="æ“ä½œé¡å‹"
    )
    parser.add_argument(
        "--name",
        help="å‚™ä»½åç¨±ï¼ˆç”¨æ–¼å‚™ä»½æˆ–æ¢å¾©ï¼‰"
    )
    parser.add_argument(
        "--target",
        help="æ¢å¾©ç›®æ¨™ç›®éŒ„æˆ–å°å‡ºç›®éŒ„"
    )
    parser.add_argument(
        "--max-backups",
        type=int,
        default=7,
        help="è‡ªå‹•å‚™ä»½ä¿ç•™æ•¸é‡ï¼ˆé è¨­: 7ï¼‰"
    )
    parser.add_argument(
        "--project-root",
        default=".",
        help="å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼ˆé è¨­: ç•¶å‰ç›®éŒ„ï¼‰"
    )
    
    args = parser.parse_args()
    
    backup_manager = MemoryBackup(args.project_root)
    
    if args.action == "backup":
        backup_manager.create_backup(args.name)
    
    elif args.action == "restore":
        if not args.name:
            print("âŒ è«‹æŒ‡å®šè¦æ¢å¾©çš„å‚™ä»½åç¨± (--name)")
        else:
            target = Path(args.target) if args.target else None
            backup_manager.restore_backup(args.name, target)
    
    elif args.action == "list":
        backups = backup_manager.list_backups()
        if backups:
            print("\nğŸ“š å¯ç”¨å‚™ä»½:")
            print("-" * 60)
            for backup in backups:
                print(f"ğŸ“¦ {backup['file']}")
                print(f"   å¤§å°: {backup['size']}")
                print(f"   å‰µå»º: {backup['created']}")
                print(f"   æ–‡ä»¶: {backup['files_count']}")
                print()
        else:
            print("â„¹ï¸  æ²’æœ‰ç™¼ç¾å‚™ä»½")
    
    elif args.action == "auto":
        backup_manager.auto_backup(args.max_backups)
    
    elif args.action == "export":
        if not args.target:
            print("âŒ è«‹æŒ‡å®šå°å‡ºç›®éŒ„ (--target)")
        else:
            backup_manager.export_memory(Path(args.target))
    
    print("\nâœ¨ æ“ä½œå®Œæˆï¼")


if __name__ == "__main__":
    main()