#!/usr/bin/env python3
"""
è¨˜æ†¶æ¸…ç†è…³æœ¬ - Memory Cleanup Script
ç”¨æ–¼æ¸…ç†å’Œç¶­è­·å°ˆæ¡ˆè¨˜æ†¶ç³»çµ±
"""

import os
import json
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Tuple

class MemoryCleanup:
    """è¨˜æ†¶æ¸…ç†ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.memory_base = self.project_root / ".kiro" / "memory"
        self.session_memory = self.memory_base / "session"
        self.archive_dir = self.project_root / ".kiro" / "archive"
        self.research_dir = self.project_root / ".kiro" / "research"
        
        # ç¢ºä¿æ­¸æª”ç›®éŒ„å­˜åœ¨
        self.archive_dir.mkdir(parents=True, exist_ok=True)
    
    def clean_session_memory(self, archive: bool = True) -> Dict:
        """æ¸…ç†æœƒè©±è¨˜æ†¶"""
        result = {
            "cleaned_files": 0,
            "archived_files": 0,
            "freed_space": 0
        }
        
        if not self.session_memory.exists():
            print("â„¹ï¸  æœƒè©±è¨˜æ†¶ç›®éŒ„ä¸å­˜åœ¨")
            return result
        
        print("ğŸ§¹ æ¸…ç†æœƒè©±è¨˜æ†¶...")
        
        # è¨ˆç®—åŸå§‹å¤§å°
        original_size = sum(
            f.stat().st_size for f in self.session_memory.rglob("*") if f.is_file()
        )
        
        if archive:
            # å‰µå»ºæ­¸æª”
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            archive_path = self.archive_dir / f"session_{timestamp}"
            archive_path.mkdir(parents=True, exist_ok=True)
            
            # ç§»å‹•æ–‡ä»¶åˆ°æ­¸æª”
            for file_path in self.session_memory.rglob("*"):
                if file_path.is_file():
                    rel_path = file_path.relative_to(self.session_memory)
                    target_path = archive_path / rel_path
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(file_path), str(target_path))
                    result["archived_files"] += 1
            
            print(f"ğŸ“¦ å·²æ­¸æª” {result['archived_files']} å€‹æ–‡ä»¶åˆ°: {archive_path.name}")
        else:
            # ç›´æ¥åˆªé™¤
            for file_path in self.session_memory.rglob("*"):
                if file_path.is_file():
                    file_path.unlink()
                    result["cleaned_files"] += 1
            
            print(f"ğŸ—‘ï¸  å·²åˆªé™¤ {result['cleaned_files']} å€‹æ–‡ä»¶")
        
        # æ¸…ç†ç©ºç›®éŒ„
        for dir_path in list(self.session_memory.rglob("*")):
            if dir_path.is_dir() and not any(dir_path.iterdir()):
                dir_path.rmdir()
        
        result["freed_space"] = original_size
        print(f"ğŸ’¾ é‡‹æ”¾ç©ºé–“: {original_size / 1024:.2f} KB")
        
        return result
    
    def clean_old_research(self, days: int = 30, archive: bool = True) -> Dict:
        """æ¸…ç†èˆŠçš„ç ”ç©¶æ–‡æª”"""
        result = {
            "cleaned_dirs": 0,
            "cleaned_files": 0,
            "freed_space": 0
        }
        
        if not self.research_dir.exists():
            print("â„¹ï¸  ç ”ç©¶ç›®éŒ„ä¸å­˜åœ¨")
            return result
        
        print(f"ğŸ§¹ æ¸…ç†è¶…é {days} å¤©çš„ç ”ç©¶æ–‡æª”...")
        
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for date_dir in self.research_dir.iterdir():
            if date_dir.is_dir():
                try:
                    # è§£æç›®éŒ„åç‚ºæ—¥æœŸ
                    dir_date = datetime.strptime(date_dir.name, "%Y-%m-%d")
                    
                    if dir_date < cutoff_date:
                        # è¨ˆç®—ç›®éŒ„å¤§å°
                        dir_size = sum(
                            f.stat().st_size for f in date_dir.rglob("*") if f.is_file()
                        )
                        file_count = sum(1 for f in date_dir.rglob("*") if f.is_file())
                        
                        if archive:
                            # æ­¸æª”åˆ° archive/research/
                            archive_path = self.archive_dir / "research" / date_dir.name
                            archive_path.parent.mkdir(parents=True, exist_ok=True)
                            shutil.move(str(date_dir), str(archive_path))
                            print(f"ğŸ“¦ æ­¸æª”: {date_dir.name} ({file_count} å€‹æ–‡ä»¶)")
                        else:
                            # ç›´æ¥åˆªé™¤
                            shutil.rmtree(date_dir)
                            print(f"ğŸ—‘ï¸  åˆªé™¤: {date_dir.name} ({file_count} å€‹æ–‡ä»¶)")
                        
                        result["cleaned_dirs"] += 1
                        result["cleaned_files"] += file_count
                        result["freed_space"] += dir_size
                
                except ValueError:
                    # ä¸æ˜¯æ—¥æœŸæ ¼å¼çš„ç›®éŒ„ï¼Œè·³é
                    continue
        
        if result["cleaned_dirs"] > 0:
            print(f"âœ… æ¸…ç†äº† {result['cleaned_dirs']} å€‹ç›®éŒ„ï¼Œ"
                  f"{result['cleaned_files']} å€‹æ–‡ä»¶")
            print(f"ğŸ’¾ é‡‹æ”¾ç©ºé–“: {result['freed_space'] / (1024*1024):.2f} MB")
        else:
            print("â„¹ï¸  æ²’æœ‰éœ€è¦æ¸…ç†çš„èˆŠç ”ç©¶æ–‡æª”")
        
        return result
    
    def clean_duplicate_decisions(self) -> Dict:
        """æ¸…ç†é‡è¤‡çš„æ±ºç­–è¨˜éŒ„"""
        result = {
            "duplicates_found": 0,
            "duplicates_removed": 0
        }
        
        global_decisions = list(self.memory_base.glob("global/decisions_*.md"))
        
        if len(global_decisions) <= 1:
            print("â„¹ï¸  æ²’æœ‰é‡è¤‡çš„æ±ºç­–è¨˜éŒ„")
            return result
        
        print(f"ğŸ” ç™¼ç¾ {len(global_decisions)} å€‹æ±ºç­–è¨˜éŒ„æ–‡ä»¶")
        
        # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼Œä¿ç•™æœ€æ–°çš„
        global_decisions.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        # ä¿ç•™æœ€æ–°çš„ï¼Œåˆªé™¤å…¶é¤˜çš„
        for old_decision in global_decisions[1:]:
            print(f"ğŸ—‘ï¸  åˆªé™¤èˆŠæ±ºç­–è¨˜éŒ„: {old_decision.name}")
            old_decision.unlink()
            result["duplicates_removed"] += 1
        
        result["duplicates_found"] = len(global_decisions) - 1
        
        return result
    
    def clean_empty_directories(self) -> int:
        """æ¸…ç†ç©ºç›®éŒ„"""
        empty_dirs_count = 0
        
        # éè¿´æ¸…ç†ç©ºç›®éŒ„
        for root, dirs, files in os.walk(self.memory_base, topdown=False):
            root_path = Path(root)
            if not files and not dirs:
                if root_path != self.memory_base:  # ä¸åˆªé™¤æ ¹ç›®éŒ„
                    print(f"ğŸ—‘ï¸  åˆªé™¤ç©ºç›®éŒ„: {root_path.relative_to(self.project_root)}")
                    root_path.rmdir()
                    empty_dirs_count += 1
        
        return empty_dirs_count
    
    def analyze_memory_usage(self) -> Dict:
        """åˆ†æè¨˜æ†¶ä½¿ç”¨æƒ…æ³"""
        usage = {
            "total_size": 0,
            "by_type": {},
            "large_files": [],
            "old_files": []
        }
        
        # çµ±è¨ˆå„é¡å‹è¨˜æ†¶ä½¿ç”¨
        for memory_type in ["global", "project", "session"]:
            memory_path = self.memory_base / memory_type
            if memory_path.exists():
                type_size = 0
                file_count = 0
                
                for file_path in memory_path.rglob("*"):
                    if file_path.is_file():
                        file_size = file_path.stat().st_size
                        type_size += file_size
                        file_count += 1
                        
                        # è¨˜éŒ„å¤§æ–‡ä»¶ï¼ˆ> 100KBï¼‰
                        if file_size > 100 * 1024:
                            usage["large_files"].append({
                                "path": str(file_path.relative_to(self.project_root)),
                                "size": f"{file_size / 1024:.2f} KB"
                            })
                        
                        # è¨˜éŒ„èˆŠæ–‡ä»¶ï¼ˆ> 30å¤©ï¼‰
                        file_age = datetime.now() - datetime.fromtimestamp(
                            file_path.stat().st_mtime
                        )
                        if file_age.days > 30:
                            usage["old_files"].append({
                                "path": str(file_path.relative_to(self.project_root)),
                                "age_days": file_age.days
                            })
                
                usage["by_type"][memory_type] = {
                    "size": type_size,
                    "files": file_count
                }
                usage["total_size"] += type_size
        
        return usage
    
    def auto_cleanup(self, session_days: int = 0, research_days: int = 30) -> Dict:
        """è‡ªå‹•æ¸…ç†ï¼ˆæ ¹æ“šç­–ç•¥ï¼‰"""
        print("ğŸ¤– é–‹å§‹è‡ªå‹•æ¸…ç†...\n")
        
        total_result = {
            "session_cleaned": False,
            "research_cleaned": 0,
            "duplicates_removed": 0,
            "empty_dirs_removed": 0,
            "total_freed_space": 0
        }
        
        # 1. åˆ†æä½¿ç”¨æƒ…æ³
        print("ğŸ“Š åˆ†æè¨˜æ†¶ä½¿ç”¨æƒ…æ³...")
        usage = self.analyze_memory_usage()
        print(f"   ç¸½å¤§å°: {usage['total_size'] / (1024*1024):.2f} MB")
        for mem_type, info in usage["by_type"].items():
            print(f"   {mem_type}: {info['size'] / 1024:.2f} KB ({info['files']} å€‹æ–‡ä»¶)")
        
        # 2. æ¸…ç†æœƒè©±è¨˜æ†¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if session_days == 0:
            print(f"\n1ï¸âƒ£  æ¸…ç†æœƒè©±è¨˜æ†¶...")
            session_result = self.clean_session_memory(archive=True)
            total_result["session_cleaned"] = True
            total_result["total_freed_space"] += session_result["freed_space"]
        
        # 3. æ¸…ç†èˆŠç ”ç©¶æ–‡æª”
        print(f"\n2ï¸âƒ£  æ¸…ç†è¶…é {research_days} å¤©çš„ç ”ç©¶æ–‡æª”...")
        research_result = self.clean_old_research(research_days, archive=True)
        total_result["research_cleaned"] = research_result["cleaned_dirs"]
        total_result["total_freed_space"] += research_result["freed_space"]
        
        # 4. æ¸…ç†é‡è¤‡æ±ºç­–
        print(f"\n3ï¸âƒ£  æ¸…ç†é‡è¤‡æ±ºç­–è¨˜éŒ„...")
        duplicate_result = self.clean_duplicate_decisions()
        total_result["duplicates_removed"] = duplicate_result["duplicates_removed"]
        
        # 5. æ¸…ç†ç©ºç›®éŒ„
        print(f"\n4ï¸âƒ£  æ¸…ç†ç©ºç›®éŒ„...")
        empty_dirs = self.clean_empty_directories()
        total_result["empty_dirs_removed"] = empty_dirs
        
        # é¡¯ç¤ºæ¸…ç†æ‘˜è¦
        print("\n" + "="*50)
        print("ğŸ“‹ æ¸…ç†æ‘˜è¦:")
        print(f"   æœƒè©±è¨˜æ†¶: {'å·²æ¸…ç†' if total_result['session_cleaned'] else 'æœªæ¸…ç†'}")
        print(f"   ç ”ç©¶æ–‡æª”: æ¸…ç†äº† {total_result['research_cleaned']} å€‹ç›®éŒ„")
        print(f"   é‡è¤‡æ±ºç­–: ç§»é™¤äº† {total_result['duplicates_removed']} å€‹")
        print(f"   ç©ºç›®éŒ„: ç§»é™¤äº† {total_result['empty_dirs_removed']} å€‹")
        print(f"   é‡‹æ”¾ç©ºé–“: {total_result['total_freed_space'] / (1024*1024):.2f} MB")
        
        return total_result


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è¨˜æ†¶ç³»çµ±æ¸…ç†å·¥å…·")
    parser.add_argument(
        "action",
        choices=["session", "research", "duplicates", "empty", "analyze", "auto"],
        help="æ¸…ç†é¡å‹"
    )
    parser.add_argument(
        "--days",
        type=int,
        default=30,
        help="æ¸…ç†Nå¤©å‰çš„å…§å®¹ï¼ˆç”¨æ–¼researchï¼Œé è¨­: 30ï¼‰"
    )
    parser.add_argument(
        "--no-archive",
        action="store_true",
        help="ç›´æ¥åˆªé™¤è€Œä¸æ­¸æª”"
    )
    parser.add_argument(
        "--project-root",
        default=".",
        help="å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼ˆé è¨­: ç•¶å‰ç›®éŒ„ï¼‰"
    )
    
    args = parser.parse_args()
    
    cleaner = MemoryCleanup(args.project_root)
    archive = not args.no_archive
    
    if args.action == "session":
        result = cleaner.clean_session_memory(archive=archive)
        print(f"\nâœ… æœƒè©±è¨˜æ†¶æ¸…ç†å®Œæˆ")
    
    elif args.action == "research":
        result = cleaner.clean_old_research(days=args.days, archive=archive)
        print(f"\nâœ… ç ”ç©¶æ–‡æª”æ¸…ç†å®Œæˆ")
    
    elif args.action == "duplicates":
        result = cleaner.clean_duplicate_decisions()
        print(f"\nâœ… é‡è¤‡æ±ºç­–æ¸…ç†å®Œæˆ")
    
    elif args.action == "empty":
        count = cleaner.clean_empty_directories()
        print(f"\nâœ… æ¸…ç†äº† {count} å€‹ç©ºç›®éŒ„")
    
    elif args.action == "analyze":
        usage = cleaner.analyze_memory_usage()
        
        print("\nğŸ“Š è¨˜æ†¶ç³»çµ±ä½¿ç”¨åˆ†æ")
        print("="*50)
        print(f"ç¸½å¤§å°: {usage['total_size'] / (1024*1024):.2f} MB\n")
        
        print("æŒ‰é¡å‹çµ±è¨ˆ:")
        for mem_type, info in usage["by_type"].items():
            print(f"  {mem_type:10} {info['size']/1024:8.2f} KB  ({info['files']} å€‹æ–‡ä»¶)")
        
        if usage["large_files"]:
            print("\nå¤§æ–‡ä»¶ (>100KB):")
            for file in usage["large_files"][:5]:
                print(f"  {file['size']:>10} - {file['path']}")
        
        if usage["old_files"]:
            print("\nèˆŠæ–‡ä»¶ (>30å¤©):")
            for file in usage["old_files"][:5]:
                print(f"  {file['age_days']:>3}å¤© - {file['path']}")
    
    elif args.action == "auto":
        result = cleaner.auto_cleanup(
            session_days=0,  # æ¸…ç†æ‰€æœ‰æœƒè©±è¨˜æ†¶
            research_days=args.days
        )
        print(f"\nâœ… è‡ªå‹•æ¸…ç†å®Œæˆ")
    
    print("\nâœ¨ æ“ä½œå®Œæˆï¼")


if __name__ == "__main__":
    main()