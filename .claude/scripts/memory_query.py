#!/usr/bin/env python3
"""
è¨˜æ†¶æŸ¥è©¢è…³æœ¬ - Memory Query Script
ç”¨æ–¼æŸ¥è©¢å’Œæœç´¢å°ˆæ¡ˆè¨˜æ†¶ç³»çµ±
"""

import os
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from collections import defaultdict

class MemoryQuery:
    """è¨˜æ†¶æŸ¥è©¢ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.memory_base = self.project_root / ".kiro" / "memory"
        self.global_memory = self.memory_base / "global"
        self.project_memory = self.memory_base / "project"
        self.session_memory = self.memory_base / "session"
        self.research_dir = self.project_root / ".kiro" / "research"
    
    def search_content(self, keyword: str, memory_type: str = "all") -> List[Dict]:
        """åœ¨è¨˜æ†¶å…§å®¹ä¸­æœç´¢é—œéµè©"""
        results = []
        
        # ç¢ºå®šæœç´¢ç¯„åœ
        if memory_type == "all":
            search_dirs = [self.global_memory, self.project_memory, self.session_memory]
        elif memory_type == "global":
            search_dirs = [self.global_memory]
        elif memory_type == "project":
            search_dirs = [self.project_memory]
        elif memory_type == "session":
            search_dirs = [self.session_memory]
        else:
            print(f"âŒ æœªçŸ¥çš„è¨˜æ†¶é¡å‹: {memory_type}")
            return results
        
        # æœç´¢æ–‡ä»¶
        for search_dir in search_dirs:
            if not search_dir.exists():
                continue
            
            for file_path in search_dir.rglob("*"):
                if file_path.is_file() and file_path.suffix in [".md", ".json", ".txt"]:
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        # æœç´¢é—œéµè©
                        if keyword.lower() in content.lower():
                            # æ‰¾å‡ºåŒ¹é…çš„è¡Œ
                            lines = content.split('\n')
                            matches = []
                            for i, line in enumerate(lines, 1):
                                if keyword.lower() in line.lower():
                                    matches.append({
                                        "line_no": i,
                                        "line": line.strip()[:100]  # åªé¡¯ç¤ºå‰100å­—ç¬¦
                                    })
                            
                            results.append({
                                "file": str(file_path.relative_to(self.project_root)),
                                "memory_type": search_dir.name,
                                "matches_count": len(matches),
                                "matches": matches[:3]  # åªé¡¯ç¤ºå‰3å€‹åŒ¹é…
                            })
                    except Exception as e:
                        print(f"âš ï¸  ç„¡æ³•è®€å–æ–‡ä»¶ {file_path}: {e}")
        
        return results
    
    def query_progress(self) -> Dict:
        """æŸ¥è©¢å°ˆæ¡ˆé€²åº¦"""
        progress_file = self.project_memory / "enhancement-progress.md"
        summary_file = self.project_memory / "progress_summary.json"
        
        result = {
            "has_progress_file": progress_file.exists(),
            "has_summary": summary_file.exists(),
            "statistics": {},
            "recent_updates": []
        }
        
        # è®€å–é€²åº¦æ‘˜è¦
        if summary_file.exists():
            with open(summary_file, 'r', encoding='utf-8') as f:
                summary = json.load(f)
                result["statistics"] = summary.get("statistics", {})
                result["last_updated"] = summary.get("last_updated", "unknown")
        
        # åˆ†æé€²åº¦æ–‡ä»¶
        if progress_file.exists():
            with open(progress_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # æå–æœ€è¿‘çš„æ›´æ–°
            for line in lines:
                if "âœ…" in line and "2025-" in line:  # æŸ¥æ‰¾åŒ…å«æ—¥æœŸçš„å®Œæˆé …
                    result["recent_updates"].append(line.strip())
        
        return result
    
    def query_decisions(self) -> List[Dict]:
        """æŸ¥è©¢æ±ºç­–è¨˜éŒ„"""
        decisions_file = self.project_memory / "decisions.md"
        decisions = []
        
        if not decisions_file.exists():
            return decisions
        
        with open(decisions_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è§£ææ±ºç­–ï¼ˆå‡è¨­æ ¼å¼ç‚º ### æ±ºç­– Nï¼šæ¨™é¡Œï¼‰
        pattern = r"### æ±ºç­– \d+ï¼š(.+?)(?=###|$)"
        matches = re.findall(pattern, content, re.DOTALL)
        
        for match in matches:
            lines = match.strip().split('\n')
            title = lines[0] if lines else "æœªå‘½åæ±ºç­–"
            
            # æå–é—œéµä¿¡æ¯
            decision_info = {
                "title": title,
                "content": '\n'.join(lines[1:10])[:200]  # å‰200å­—ç¬¦
            }
            decisions.append(decision_info)
        
        return decisions
    
    def query_recent_research(self, days: int = 7) -> List[Dict]:
        """æŸ¥è©¢æœ€è¿‘çš„ç ”ç©¶æ–‡æª”"""
        research_items = []
        
        if not self.research_dir.exists():
            return research_items
        
        # ç²å–æ—¥æœŸç¯„åœ
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # æŸ¥æ‰¾æ—¥æœŸç›®éŒ„
        for date_dir in self.research_dir.iterdir():
            if date_dir.is_dir():
                try:
                    # è§£æç›®éŒ„åç‚ºæ—¥æœŸ
                    dir_date = datetime.strptime(date_dir.name, "%Y-%m-%d")
                    
                    if start_date <= dir_date <= end_date:
                        # çµ±è¨ˆè©²æ—¥æœŸçš„ç ”ç©¶æ–‡æª”
                        md_files = list(date_dir.glob("*.md"))
                        if md_files:
                            research_items.append({
                                "date": date_dir.name,
                                "files_count": len(md_files),
                                "files": [f.name for f in md_files]
                            })
                except ValueError:
                    # ä¸æ˜¯æ—¥æœŸæ ¼å¼çš„ç›®éŒ„ï¼Œè·³é
                    continue
        
        return sorted(research_items, key=lambda x: x["date"], reverse=True)
    
    def query_specs_status(self) -> List[Dict]:
        """æŸ¥è©¢åŠŸèƒ½è¦æ ¼ç‹€æ…‹"""
        specs_dir = self.project_root / ".kiro" / "specs"
        specs_info = []
        
        if not specs_dir.exists():
            return specs_info
        
        for spec_dir in specs_dir.iterdir():
            if spec_dir.is_dir():
                spec_json = spec_dir / "spec.json"
                
                info = {
                    "feature": spec_dir.name,
                    "has_spec": spec_json.exists(),
                    "files": []
                }
                
                # è®€å–è¦æ ¼ç‹€æ…‹
                if spec_json.exists():
                    with open(spec_json, 'r', encoding='utf-8') as f:
                        spec_data = json.load(f)
                        info["status"] = spec_data.get("status", "unknown")
                        info["created"] = spec_data.get("created", "unknown")
                
                # çµ±è¨ˆæ–‡ä»¶
                for file_path in spec_dir.glob("*.md"):
                    info["files"].append(file_path.name)
                
                specs_info.append(info)
        
        return specs_info
    
    def generate_memory_map(self) -> str:
        """ç”Ÿæˆè¨˜æ†¶ç³»çµ±åœ°åœ–"""
        lines = ["# è¨˜æ†¶ç³»çµ±åœ°åœ–\n"]
        lines.append(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # çµ±è¨ˆå„å±¤è¨˜æ†¶
        memory_stats = {}
        for memory_type, path in [
            ("å…¨å±€è¨˜æ†¶", self.global_memory),
            ("å°ˆæ¡ˆè¨˜æ†¶", self.project_memory),
            ("æœƒè©±è¨˜æ†¶", self.session_memory)
        ]:
            if path.exists():
                files = list(path.glob("**/*"))
                file_count = sum(1 for f in files if f.is_file())
                total_size = sum(f.stat().st_size for f in files if f.is_file())
                
                memory_stats[memory_type] = {
                    "files": file_count,
                    "size": total_size
                }
        
        # ç”Ÿæˆçµ±è¨ˆåœ–
        lines.append("## è¨˜æ†¶åˆ†å¸ƒ\n")
        lines.append("```")
        for mem_type, stats in memory_stats.items():
            size_mb = stats["size"] / (1024 * 1024)
            bar_length = int(stats["files"] / 2)  # ç°¡å–®çš„æ¢å½¢åœ–
            bar = "â–ˆ" * min(bar_length, 30)
            lines.append(f"{mem_type:10} [{stats['files']:3}æª”] {bar} ({size_mb:.2f}MB)")
        lines.append("```\n")
        
        # æœ€è¿‘æ´»å‹•
        lines.append("## æœ€è¿‘æ´»å‹•\n")
        
        # æŸ¥è©¢æœ€è¿‘ç ”ç©¶
        recent_research = self.query_recent_research(3)
        if recent_research:
            lines.append("### æœ€è¿‘ç ”ç©¶")
            for research in recent_research[:3]:
                lines.append(f"- {research['date']}: {research['files_count']} å€‹æ–‡æª”")
        
        # æŸ¥è©¢é€²åº¦
        progress = self.query_progress()
        if progress["statistics"]:
            lines.append("\n### é€²åº¦çµ±è¨ˆ")
            stats = progress["statistics"]
            lines.append(f"- å·²å®Œæˆ: {stats.get('completed', 0)}")
            lines.append(f"- é€²è¡Œä¸­: {stats.get('in_progress', 0)}")
            lines.append(f"- å¾…è™•ç†: {stats.get('pending', 0)}")
        
        return "\n".join(lines)
    
    def smart_query(self, query: str) -> Dict:
        """æ™ºèƒ½æŸ¥è©¢ï¼ˆæ ¹æ“šæŸ¥è©¢å…§å®¹è‡ªå‹•é¸æ“‡æŸ¥è©¢é¡å‹ï¼‰"""
        result = {
            "query": query,
            "results": {}
        }
        
        # åˆ¤æ–·æŸ¥è©¢é¡å‹
        if "é€²åº¦" in query or "progress" in query.lower():
            result["results"]["progress"] = self.query_progress()
        
        if "æ±ºç­–" in query or "decision" in query.lower():
            result["results"]["decisions"] = self.query_decisions()
        
        if "ç ”ç©¶" in query or "research" in query.lower():
            result["results"]["research"] = self.query_recent_research()
        
        if "è¦æ ¼" in query or "spec" in query.lower():
            result["results"]["specs"] = self.query_specs_status()
        
        # å¦‚æœæ²’æœ‰ç‰¹å®šé¡å‹ï¼Œé€²è¡Œå…§å®¹æœç´¢
        if not result["results"]:
            # æå–å¯èƒ½çš„é—œéµè©
            keywords = [w for w in query.split() if len(w) > 2]
            for keyword in keywords[:3]:  # æœ€å¤šæœç´¢3å€‹é—œéµè©
                search_results = self.search_content(keyword)
                if search_results:
                    result["results"][f"search_{keyword}"] = search_results
        
        return result


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è¨˜æ†¶ç³»çµ±æŸ¥è©¢å·¥å…·")
    parser.add_argument(
        "query_type",
        choices=["search", "progress", "decisions", "research", "specs", "map", "smart"],
        help="æŸ¥è©¢é¡å‹"
    )
    parser.add_argument(
        "keyword",
        nargs="?",
        help="æœç´¢é—œéµè©æˆ–æ™ºèƒ½æŸ¥è©¢å…§å®¹"
    )
    parser.add_argument(
        "--memory-type",
        choices=["all", "global", "project", "session"],
        default="all",
        help="è¨˜æ†¶é¡å‹ï¼ˆç”¨æ–¼æœç´¢ï¼‰"
    )
    parser.add_argument(
        "--days",
        type=int,
        default=7,
        help="æŸ¥è©¢æœ€è¿‘Nå¤©çš„ç ”ç©¶ï¼ˆé è¨­: 7ï¼‰"
    )
    parser.add_argument(
        "--project-root",
        default=".",
        help="å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼ˆé è¨­: ç•¶å‰ç›®éŒ„ï¼‰"
    )
    
    args = parser.parse_args()
    
    query_manager = MemoryQuery(args.project_root)
    
    if args.query_type == "search":
        if not args.keyword:
            print("âŒ è«‹æä¾›æœç´¢é—œéµè©")
        else:
            results = query_manager.search_content(args.keyword, args.memory_type)
            if results:
                print(f"\nğŸ” æ‰¾åˆ° {len(results)} å€‹åŒ…å« '{args.keyword}' çš„æ–‡ä»¶:\n")
                for result in results:
                    print(f"ğŸ“„ {result['file']}")
                    print(f"   é¡å‹: {result['memory_type']}")
                    print(f"   åŒ¹é…: {result['matches_count']} è™•")
                    for match in result['matches']:
                        print(f"   L{match['line_no']}: {match['line']}")
                    print()
            else:
                print(f"â„¹ï¸  æ²’æœ‰æ‰¾åˆ°åŒ…å« '{args.keyword}' çš„å…§å®¹")
    
    elif args.query_type == "progress":
        progress = query_manager.query_progress()
        print("\nğŸ“Š å°ˆæ¡ˆé€²åº¦æŸ¥è©¢çµæœ:\n")
        if progress["statistics"]:
            print("çµ±è¨ˆæ•¸æ“š:")
            for key, value in progress["statistics"].items():
                print(f"  - {key}: {value}")
        if progress["recent_updates"]:
            print("\næœ€è¿‘æ›´æ–°:")
            for update in progress["recent_updates"][:5]:
                print(f"  {update}")
    
    elif args.query_type == "decisions":
        decisions = query_manager.query_decisions()
        if decisions:
            print(f"\nğŸ“‹ æ‰¾åˆ° {len(decisions)} å€‹æ±ºç­–è¨˜éŒ„:\n")
            for i, decision in enumerate(decisions, 1):
                print(f"{i}. {decision['title']}")
                print(f"   {decision['content'][:100]}...")
                print()
        else:
            print("â„¹ï¸  æ²’æœ‰æ‰¾åˆ°æ±ºç­–è¨˜éŒ„")
    
    elif args.query_type == "research":
        research = query_manager.query_recent_research(args.days)
        if research:
            print(f"\nğŸ“š æœ€è¿‘ {args.days} å¤©çš„ç ”ç©¶æ–‡æª”:\n")
            for item in research:
                print(f"ğŸ“… {item['date']} ({item['files_count']} å€‹æ–‡æª”)")
                for file in item['files']:
                    print(f"   - {file}")
                print()
        else:
            print(f"â„¹ï¸  æœ€è¿‘ {args.days} å¤©æ²’æœ‰ç ”ç©¶æ–‡æª”")
    
    elif args.query_type == "specs":
        specs = query_manager.query_specs_status()
        if specs:
            print(f"\nğŸ“¦ åŠŸèƒ½è¦æ ¼ç‹€æ…‹ ({len(specs)} å€‹):\n")
            for spec in specs:
                status = spec.get('status', 'unknown')
                print(f"ğŸ¯ {spec['feature']} [{status}]")
                if spec['files']:
                    print(f"   æ–‡ä»¶: {', '.join(spec['files'])}")
                print()
        else:
            print("â„¹ï¸  æ²’æœ‰æ‰¾åˆ°åŠŸèƒ½è¦æ ¼")
    
    elif args.query_type == "map":
        memory_map = query_manager.generate_memory_map()
        print(memory_map)
    
    elif args.query_type == "smart":
        if not args.keyword:
            print("âŒ è«‹æä¾›æŸ¥è©¢å…§å®¹")
        else:
            result = query_manager.smart_query(args.keyword)
            print(f"\nğŸ¤– æ™ºèƒ½æŸ¥è©¢: '{args.keyword}'\n")
            
            if result["results"]:
                for result_type, data in result["results"].items():
                    print(f"### {result_type}")
                    if isinstance(data, list):
                        for item in data[:3]:
                            print(f"  - {item}")
                    elif isinstance(data, dict):
                        for key, value in list(data.items())[:5]:
                            print(f"  - {key}: {value}")
                    print()
            else:
                print("â„¹ï¸  æ²’æœ‰æ‰¾åˆ°ç›¸é—œçµæœ")
    
    print("\nâœ¨ æŸ¥è©¢å®Œæˆï¼")


if __name__ == "__main__":
    main()